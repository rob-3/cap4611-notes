# Classification vs Regression

- Classification is for discrete
- Regression: output is continuous

# Toy Data

- MNIST and Iris
- MNIST is a flower dataset
- Fashion MNIST is a clothes dataset

- Binary classifier: two options (email is spam or not)
- if C is not mutually exclusive, multilabel problem

- Accuracy = # correct / # total
- Misclassification = # incorrect / # total
- These are simplistic measures that are bad for imbalanced datasets

- Confusion Matrix
  - Matrix of prediction vs actual
  - 4 things: True positive, true negative, false positive, false negative
  - Precision: tp / (tp + fp) how many positive were correct?
  - Recall: tp / (tp + fn) how many positive in the dataset did I find?
  - True positive rate: tpr = tp / (tp + fn) same as recall
  - True negative rate: tnr = tn / (tn + fp) same as recall
  - False positive rate: fpr = fp / (tn + fp) same as recall
  - False negative rate: fnr = fn / (tp + fn) same as recall
  - F1 score = 2 / (1/precision + 1/recall) = tp / (tp + (fn+fp)/2)
    - Balances precision and recall

# The Precision-Recall Tradeoff
