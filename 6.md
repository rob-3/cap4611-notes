# ROC Curve

- Plot of true positive rate vs false positive rate
- Useful for binary classifiers
- Usually we use the area under the ROC curve for comparisons
  - Bigger is better; 1 is perfect

# Which Curve Do We Use

- Prefer P/R curve if positive classifications are rare
  - We care more about false positives than false negatives
- Prefer ROC curve in all other cases

# Multiclass Classification

- (as opposed to binary)
- Decision tree, naive bayes = no problem
- Logistic regression, Support Vector Machine = only work for binary
  - One vs rest/one vs all: just do a binary classification for every trait
  - One vs one: train O(n^2) classifiers to check every possible pairing
    - This can be better if your classifier scales poorly because you can use less data for each individual classifier
- Multilabels: use a weighted average over multiple columns of a classification matrix

# Classification Process

1. Get data
1. EDA
1. ???
1. Evaluate
1. Profit

# Regression

We have data, we want a line that can predict values

4 ways:

1. SSE = sum of squared errors (divide by 2!)
1. MSE = mean squared error
1. RMSE = root mean squared error = sqrt(MSE)
1. MAE = mean absolute error (like MSE but use abs instead of sqrt)
1. R^2 = SSE/TSS where TSS (total sum of squares) = 1/2 * \sum square error
